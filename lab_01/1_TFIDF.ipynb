{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uczenie g≈Çƒôbokie ‚Äì przetwarzanie tekstu ‚Äì laboratoria\n",
    "# 1. TF‚ÄìIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zbi√≥r dokument√≥w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = ['Ala lubi zwierzƒôta i ma kota oraz psa!',\n",
    "             'Ola lubi zwierzƒôta oraz ma kota a tak≈ºe chomika!',\n",
    "             'I Jan je≈∫dzi na rowerze.',\n",
    "             '2 wojna ≈õwiatowa by≈Ça wielkim konfliktem zbrojnym',\n",
    "             'Tomek lubi psy, ma psa  i je≈∫dzi na motorze i rowerze.',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czego potrzebujemy?\n",
    "\n",
    "- Chcemy zamieniƒá teksty na zbi√≥r s≈Ç√≥w."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùî Pytania\n",
    "\n",
    "- Czy do stokenizowania tekstu mo≈ºemy u≈ºyƒá `document.split(' ')`?\n",
    "- Jakie trudno≈õci mo≈ºemy napotkaƒá?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_str_cleaned(str_dirty):\n",
    "    punctuation = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    new_str = str_dirty.lower()\n",
    "    new_str = re.sub(' +', ' ', new_str)\n",
    "    for char in punctuation:\n",
    "        new_str = new_str.replace(char,'')\n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_document = get_str_cleaned(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ala lubi zwierzƒôta i ma kota oraz psa'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_str(document):\n",
    "    return document.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ala', 'lubi', 'zwierzƒôta', 'i', 'ma', 'kota', 'oraz', 'psa']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_str(sample_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_cleaned = [get_str_cleaned(document) for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ala lubi zwierzƒôta i ma kota oraz psa',\n",
       " 'ola lubi zwierzƒôta oraz ma kota a tak≈ºe chomika',\n",
       " 'i jan je≈∫dzi na rowerze',\n",
       " '2 wojna ≈õwiatowa by≈Ça wielkim konfliktem zbrojnym',\n",
       " 'tomek lubi psy ma psa i je≈∫dzi na motorze i rowerze']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_tokenized = [tokenize_str(d) for d in documents_cleaned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ala', 'lubi', 'zwierzƒôta', 'i', 'ma', 'kota', 'oraz', 'psa'],\n",
       " ['ola', 'lubi', 'zwierzƒôta', 'oraz', 'ma', 'kota', 'a', 'tak≈ºe', 'chomika'],\n",
       " ['i', 'jan', 'je≈∫dzi', 'na', 'rowerze'],\n",
       " ['2', 'wojna', '≈õwiatowa', 'by≈Ça', 'wielkim', 'konfliktem', 'zbrojnym'],\n",
       " ['tomek',\n",
       "  'lubi',\n",
       "  'psy',\n",
       "  'ma',\n",
       "  'psa',\n",
       "  'i',\n",
       "  'je≈∫dzi',\n",
       "  'na',\n",
       "  'motorze',\n",
       "  'i',\n",
       "  'rowerze']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùî Pytania\n",
    "\n",
    "- Jaki jest nastƒôpny krok w celu stworzenia wekt√≥r√≥w TF lub TF‚ÄìIDF?\n",
    "- Jakie wielko≈õci bƒôdzie wektor TF lub TF‚ÄìIDF?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stworzenie s≈Çownika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "for document in documents_tokenized:\n",
    "    for word in document:\n",
    "        vocabulary.append(word)\n",
    "vocabulary = sorted(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2',\n",
       " 'a',\n",
       " 'ala',\n",
       " 'by≈Ça',\n",
       " 'chomika',\n",
       " 'i',\n",
       " 'jan',\n",
       " 'je≈∫dzi',\n",
       " 'konfliktem',\n",
       " 'kota',\n",
       " 'lubi',\n",
       " 'ma',\n",
       " 'motorze',\n",
       " 'na',\n",
       " 'ola',\n",
       " 'oraz',\n",
       " 'psa',\n",
       " 'psy',\n",
       " 'rowerze',\n",
       " 'tak≈ºe',\n",
       " 'tomek',\n",
       " 'wielkim',\n",
       " 'wojna',\n",
       " 'zbrojnym',\n",
       " 'zwierzƒôta',\n",
       " '≈õwiatowa']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Zadanie **1.1** *(1 pkt)*\n",
    "\n",
    "Napisz funkcjƒô `word_to_index(word: str)`, kt√≥ra dla danego s≈Çowa zwraca wektor jednostkowy (*one-hot vector*) w postaci `numpy.array`.\n",
    "\n",
    "Przyjmij, ≈ºe s≈Çownik dany jest za pomocƒÖ zmiennej globalnej `vocabulary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_index(word: str) -> np.array:\n",
    "    vector = np.zeros(len(vocabulary))\n",
    "    if word in vocabulary:\n",
    "        index = vocabulary.index(word)\n",
    "        vector[index] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index('psa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Zadanie **1.2** *(1 pkt)*\n",
    "\n",
    "Napisz funkcjƒô, kt√≥ra zamienia listƒô s≈Ç√≥w na wektor TF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(document: list) -> np.array:\n",
    "    vector = np.zeros(len(vocabulary))\n",
    "    for word in document:\n",
    "        if word in vocabulary:\n",
    "            index = vocabulary.index(word)\n",
    "            vector[index] += 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf(documents_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_vectorized = list()\n",
    "for document in documents_tokenized:\n",
    "    document_vector = tf(document)\n",
    "    documents_vectorized.append(document_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 1., 1., 0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 2., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
       "        1., 1., 0., 1., 0., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idf = np.zeros(len(vocabulary))\n",
    "idf = len(documents_vectorized) / np.sum(np.array(documents_vectorized) != 0,axis=0)\n",
    "display(idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Zadanie **1.3** *(1 pkt)*\n",
    "\n",
    "Napisz funkcjƒô, kt√≥ra zwraca podobie≈Ñstwo kosinusowe miƒôdzy dwoma dokumentami w postaci zwektoryzowanej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(query: np.array, document: np.array) -> float:\n",
    "    numerator = np.dot(query, document)\n",
    "    denominator = np.linalg.norm(query) * np.linalg.norm(document)\n",
    "    if denominator == 0:\n",
    "        return 0.0\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ala lubi zwierzƒôta i ma kota oraz psa!'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_vectorized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ola lubi zwierzƒôta oraz ma kota a tak≈ºe chomika!'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_vectorized[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5892556509887895"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(documents_vectorized[0], documents_vectorized[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prosta wyszukiwarka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_query(query):\n",
    "    \"\"\"Funkcja, kt√≥ra czy≈õci i tokenizuje zapytanie\"\"\"\n",
    "    query_vector = tf(tokenize_str(get_str_cleaned(query)))\n",
    "    return query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999999999999999"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(transform_query('psa kota'), documents_vectorized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ala lubi zwierzƒôta i ma kota oraz psa!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.4999999999999999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Ola lubi zwierzƒôta oraz ma kota a tak≈ºe chomika!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.2357022603955158"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'I Jan je≈∫dzi na rowerze.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2 wojna ≈õwiatowa by≈Ça wielkim konfliktem zbrojnym'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Tomek lubi psy, ma psa  i je≈∫dzi na motorze i rowerze.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.19611613513818402"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = 'psa kota'\n",
    "for i in range(len(documents)):\n",
    "    display(documents[i])\n",
    "    display(similarity(transform_query(query), documents_vectorized[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ala lubi zwierzƒôta i ma kota oraz psa!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Ola lubi zwierzƒôta oraz ma kota a tak≈ºe chomika!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'I Jan je≈∫dzi na rowerze.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.4472135954999579"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2 wojna ≈õwiatowa by≈Ça wielkim konfliktem zbrojnym'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Tomek lubi psy, ma psa  i je≈∫dzi na motorze i rowerze.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.2773500981126146"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dlatego potrzebujemy mianownik w cosine similarity\n",
    "query = 'rowerze'\n",
    "for i in range(len(documents)):\n",
    "    display(documents[i])\n",
    "    display(similarity(transform_query(query), documents_vectorized[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ala lubi zwierzƒôta i ma kota oraz psa!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.35355339059327373"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Ola lubi zwierzƒôta oraz ma kota a tak≈ºe chomika!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'I Jan je≈∫dzi na rowerze.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.4472135954999579"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2 wojna ≈õwiatowa by≈Ça wielkim konfliktem zbrojnym'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Tomek lubi psy, ma psa  i je≈∫dzi na motorze i rowerze.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5547001962252291"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dlatego potrzebujemy term frequency ‚Üí wiecej znaczy bardziej dopasowany dokument\n",
    "query = 'i'\n",
    "for i in range(len(documents)):\n",
    "    display(documents[i])\n",
    "    display(similarity(transform_query(query), documents_vectorized[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ala lubi zwierzƒôta i ma kota oraz psa!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.24999999999999994"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Ola lubi zwierzƒôta oraz ma kota a tak≈ºe chomika!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.2357022603955158"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'I Jan je≈∫dzi na rowerze.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.31622776601683794"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2 wojna ≈õwiatowa by≈Ça wielkim konfliktem zbrojnym'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Tomek lubi psy, ma psa  i je≈∫dzi na motorze i rowerze.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.39223227027636803"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dlatego IDF - ≈ºeby wa≈ºniejsze s≈Çowa mia≈Ç wiƒôkszƒÖ wagƒô\n",
    "query = 'i chomika'\n",
    "for i in range(len(documents)):\n",
    "    display(documents[i])\n",
    "    display(similarity(transform_query(query), documents_vectorized[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naiwne przeszukiwanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents = list() \n",
    "for document in newsgroups:\n",
    "    if 'car' in document:\n",
    "        all_documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(all_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: guykuo@carson.u.washington.edu (Guy Kuo)\n",
      "Subject: SI Clock Poll - Final Call\n",
      "Summary: Final call for SI clock reports\n",
      "Keywords: SI,acceleration,clock,upgrade\n",
      "Article-I.D.: shelley.1qvfo9INNc3s\n",
      "Organization: University of Washington\n",
      "Lines: 11\n",
      "NNTP-Posting-Host: carson.u.washington.edu\n",
      "\n",
      "A fair number of brave souls who upgraded their SI clock oscillator have\n",
      "shared their experiences for this poll. Please send a brief message detailing\n",
      "your experiences with the procedure. Top speed attained, CPU rated speed,\n",
      "add on cards and adapters, heat sinks, hour of usage per day, floppy disk\n",
      "functionality with 800 and 1.4 m floppies are especially requested.\n",
      "\n",
      "I will be summarizing in the next two days, so please add to the network\n",
      "knowledge base if you have done the clock upgrade and haven't answered this\n",
      "poll. Thanks.\n",
      "\n",
      "Guy Kuo <guykuo@u.washington.edu>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(all_documents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ùî Pytanie\n",
    "\n",
    "Jakie sƒÖ problemy z takim podej≈õciem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF‚ÄìIDF i odleg≈Ço≈õƒá kosinusowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_vectors = vectorizer.fit_transform(newsgroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 1787565 stored elements and shape (11314, 130107)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 89 stored elements and shape (1, 130107)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vectors[0].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vectors[0:4].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = 'speed'\n",
    "#query_str = 'speed car'\n",
    "#query_str = 'spider man'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26949927 0.3491801  0.44292083 0.47784165]\n",
      "[4517 5509 2116 9921]\n",
      "From: ray@netcom.com (Ray Fischer)\n",
      "Subject: Re: x86 ~= 680x0 ??  (How do they compare?)\n",
      "Organization: Netcom. San Jose, California\n",
      "Distribution: usa\n",
      "Lines: 36\n",
      "\n",
      "dhk@ubbpc.uucp (Dave Kitabjian) writes ...\n",
      ">I'm sure Intel and Motorola are competing neck-and-neck for \n",
      ">crunch-power, but for a given clock speed, how do we rank the\n",
      ">following (from 1st to 6th):\n",
      ">  486\t\t68040\n",
      ">  386\t\t68030\n",
      ">  286\t\t68020\n",
      "\n",
      "040 486 030 386 020 286\n",
      "\n",
      ">While you're at it, where will the following fit into the list:\n",
      ">  68060\n",
      ">  Pentium\n",
      ">  PowerPC\n",
      "\n",
      "060 fastest, then Pentium, with the first versions of the PowerPC\n",
      "somewhere in the vicinity.\n",
      "\n",
      ">And about clock speed:  Does doubling the clock speed double the\n",
      ">overall processor speed?  And fill in the __'s below:\n",
      ">  68030 @ __ MHz = 68040 @ __ MHz\n",
      "\n",
      "No.  Computer speed is only partly dependent of processor/clock speed.\n",
      "Memory system speed play a large role as does video system speed and\n",
      "I/O speed.  As processor clock rates go up, the speed of the memory\n",
      "system becomes the greatest factor in the overall system speed.  If\n",
      "you have a 50MHz processor, it can be reading another word from memory\n",
      "every 20ns.  Sure, you can put all 20ns memory in your computer, but\n",
      "it will cost 10 times as much as the slower 80ns SIMMs.\n",
      "\n",
      "And roughly, the 68040 is twice as fast at a given clock\n",
      "speed as is the 68030.\n",
      "\n",
      "-- \n",
      "Ray Fischer                   \"Convictions are more dangerous enemies of truth\n",
      "ray@netcom.com                 than lies.\"  -- Friedrich Nietzsche\n",
      "\n",
      "0.47784164650209066\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "From: rvenkate@ux4.cso.uiuc.edu (Ravikuma Venkateswar)\n",
      "Subject: Re: x86 ~= 680x0 ?? (How do they compare?)\n",
      "Distribution: usa\n",
      "Organization: University of Illinois at Urbana\n",
      "Lines: 59\n",
      "\n",
      "ray@netcom.com (Ray Fischer) writes:\n",
      "\n",
      ">dhk@ubbpc.uucp (Dave Kitabjian) writes ...\n",
      ">>I'm sure Intel and Motorola are competing neck-and-neck for \n",
      ">>crunch-power, but for a given clock speed, how do we rank the\n",
      ">>following (from 1st to 6th):\n",
      ">>  486\t\t68040\n",
      ">>  386\t\t68030\n",
      ">>  286\t\t68020\n",
      "\n",
      ">040 486 030 386 020 286\n",
      "\n",
      "How about some numbers here? Some kind of benchmark?\n",
      "If you want, let me start it - 486DX2-66 - 32 SPECint92, 16 SPECfp92 .\n",
      "\n",
      ">>While you're at it, where will the following fit into the list:\n",
      ">>  68060\n",
      ">>  Pentium\n",
      ">>  PowerPC\n",
      "\n",
      ">060 fastest, then Pentium, with the first versions of the PowerPC\n",
      ">somewhere in the vicinity.\n",
      "\n",
      "Numbers? Pentium @66MHz - 65 SPECint92, 57 SPECfp92 .\n",
      "\t PowerPC @66MHz - 50 SPECint92, 80 SPECfp92 . (Note this is the 601)\n",
      "        (Alpha @150MHz  - 74 SPECint92,126 SPECfp92 - just for comparison)\n",
      "\n",
      ">>And about clock speed:  Does doubling the clock speed double the\n",
      ">>overall processor speed?  And fill in the __'s below:\n",
      ">>  68030 @ __ MHz = 68040 @ __ MHz\n",
      "\n",
      ">No.  Computer speed is only partly dependent of processor/clock speed.\n",
      ">Memory system speed play a large role as does video system speed and\n",
      ">I/O speed.  As processor clock rates go up, the speed of the memory\n",
      ">system becomes the greatest factor in the overall system speed.  If\n",
      ">you have a 50MHz processor, it can be reading another word from memory\n",
      ">every 20ns.  Sure, you can put all 20ns memory in your computer, but\n",
      ">it will cost 10 times as much as the slower 80ns SIMMs.\n",
      "\n",
      "Not in a clock-doubled system. There isn't a doubling in performance, but\n",
      "it _is_ quite significant. Maybe about a 70% increase in performance.\n",
      "\n",
      "Besides, for 0 wait state performance, you'd need a cache anyway. I mean,\n",
      "who uses a processor that runs at the speed of 80ns SIMMs? Note that this\n",
      "memory speed corresponds to a clock speed of 12.5 MHz.\n",
      "\n",
      ">And roughly, the 68040 is twice as fast at a given clock\n",
      ">speed as is the 68030.\n",
      "\n",
      "Numbers?\n",
      "\n",
      ">-- \n",
      ">Ray Fischer                   \"Convictions are more dangerous enemies of truth\n",
      ">ray@netcom.com                 than lies.\"  -- Friedrich Nietzsche\n",
      "-- \n",
      "Ravikumar Venkateswar\n",
      "rvenkate@uiuc.edu\n",
      "\n",
      "A pun is a no' blessed form of whit.\n",
      "\n",
      "0.44292082969477664\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "From: ray@netcom.com (Ray Fischer)\n",
      "Subject: Re: x86 ~= 680x0 ?? (How do they compare?)\n",
      "Organization: Netcom. San Jose, California\n",
      "Distribution: usa\n",
      "Lines: 30\n",
      "\n",
      "rvenkate@ux4.cso.uiuc.edu (Ravikuma Venkateswar) writes ...\n",
      ">ray@netcom.com (Ray Fischer) writes:\n",
      ">>040 486 030 386 020 286\n",
      ">\n",
      ">How about some numbers here? Some kind of benchmark?\n",
      "\n",
      "Benchmarks are for marketing dweebs and CPU envy.  OK, if it will make\n",
      "you happy, the 486 is faster than the 040.  BFD.  Both architectures\n",
      "are nearing then end of their lifetimes.  And especially with the x86\n",
      "architecture: good riddance.\n",
      "\n",
      ">Besides, for 0 wait state performance, you'd need a cache anyway. I mean,\n",
      ">who uses a processor that runs at the speed of 80ns SIMMs? Note that this\n",
      ">memory speed corresponds to a clock speed of 12.5 MHz.\n",
      "\n",
      "The point being the processor speed is only one of many aspects of a\n",
      "computers performance.  Clock speed, processor, memory speed, CPU\n",
      "architecture, I/O systems, even the application program all contribute \n",
      "to the overall system performance.\n",
      "\n",
      ">>And roughly, the 68040 is twice as fast at a given clock\n",
      ">>speed as is the 68030.\n",
      ">\n",
      ">Numbers?\n",
      "\n",
      "Look them up yourself.\n",
      "\n",
      "-- \n",
      "Ray Fischer                   \"Convictions are more dangerous enemies of truth\n",
      "ray@netcom.com                 than lies.\"  -- Friedrich Nietzsche\n",
      "\n",
      "0.3491800997095307\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "From: mb4008@cehp11 (Morgan J Bullard)\n",
      "Subject: Re: speeding up windows\n",
      "Keywords: speed\n",
      "Organization: University of Illinois at Urbana\n",
      "Lines: 30\n",
      "\n",
      "djserian@flash.LakeheadU.Ca (Reincarnation of Elvis) writes:\n",
      "\n",
      ">I have a 386/33 with 8 megs of memory\n",
      "\n",
      ">I have noticed that lately when I use programs like WpfW or Corel Draw\n",
      ">my computer \"boggs\" down and becomes really sluggish!\n",
      "\n",
      ">What can I do to increase performance?  What should I turn on or off\n",
      "\n",
      ">Will not loading wallpapers or stuff like that help when it comes to\n",
      ">the running speed of windows and the programs that run under it?\n",
      "\n",
      ">Thanx in advance\n",
      "\n",
      ">Derek\n",
      "\n",
      "1) make sure your hard drive is defragmented. This will speed up more than \n",
      "   just windows BTW.  Use something like Norton's or PC Tools.\n",
      "2) I _think_ that leaving the wall paper out will use less RAM and therefore\n",
      "   will speed up your machine but I could very will be wrong on this.\n",
      "There's a good chance you've already done this but if not it may speed things\n",
      "up.  good luck\n",
      "\t\t\t\tMorgan Bullard mb4008@coewl.cen.uiuc.edu\n",
      "\t\t\t\t\t  or   mjbb@uxa.cso.uiuc.edu\n",
      "\n",
      ">--\n",
      ">$_    /|$Derek J.P. Serianni $ E-Mail : djserian@flash.lakeheadu.ca           $ \n",
      ">$\\'o.O' $Sociologist         $ It's 106 miles to Chicago,we've got a full tank$\n",
      ">$=(___)=$Lakehead University $ of gas, half a pack of cigarettes,it's dark,and$\n",
      ">$   U   $Thunder Bay, Ontario$ we're wearing sunglasses. -Elwood Blues        $  \n",
      "\n",
      "0.2694992739388691\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query_vector = vectorizer.transform([query_str])\n",
    "similarities = sklearn.metrics.pairwise.cosine_similarity(query_vector,document_vectors)\n",
    "print(np.sort(similarities)[0][-4:])\n",
    "print(similarities.argsort()[0][-4:])\n",
    "\n",
    "for i in range (1,5):\n",
    "    print(newsgroups[similarities.argsort()[0][-i]])\n",
    "    print(np.sort(similarities)[0,-i])\n",
    "    print('-'*100)\n",
    "    print('-'*100)\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Zadanie **1.4** *(4 pkt.)*\n",
    "\n",
    "Wybierz zbi√≥r tekstowy, kt√≥ry ma conajmniej 10000 dokument√≥w (inny ni≈º w tym przyk≈Çadzie).\n",
    "Na jego podstawie stw√≥rz wyszukiwarkƒô wykorzystujƒÖcƒÖ TF‚ÄìIDF i podobie≈Ñstwo kosinusowe do oceny podobie≈Ñstwa dokument√≥w. Wyszukiwarka powinna zwracaƒá kilka posortowanych najbardziej pasujƒÖcych dokument√≥w razem ze score'ami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def search(query, top_n=20):\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(query_vector, document_vectors).flatten()\n",
    "    top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "    for idx in top_indices:\n",
    "        print(f\"Similarity: {similarities[idx]:.4f}\")\n",
    "        print(f\"Document: {documents[idx]}\")\n",
    "        print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.5239\n",
      "Document: Iran Plans to Launch Satellite by May 2005 (Reuters) Reuters - Iran said Thursday it would launch its\\first satellite into space by May 2005, state television\\reported.\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.4865\n",
      "Document: Satellite launch the fortieth in past 8 years With the third  quot;ZY-2 quot; research satellite successfully entering into orbit on Saturday morning, China has accomplished the launch of its 40th satellite since October 1996.\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.4625\n",
      "Document: NASA delays DART launch NASA and Orbital Sciences Corp. postponed Tuesday #39;s launch of a robot spacecraft after the satellite to which it was supposed to attach temporarily lost its global positioning reception.\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.4586\n",
      "Document: Robotic Craft's Launch Delayed At Least 2 Days NASA postponed for at least two days the launch of its robotic satellite-chasing spacecraft because the target satellite temporarily lost reception of a key navigational signal, the agency said Tuesday.\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.4575\n",
      "Document: Robotic Craft #39;s Launch Delayed At Least 2 Days NASA postponed for at least two days the launch of its robotic satellite-chasing spacecraft because the target satellite temporarily lost reception of a key navigational signal, the agency said yesterday.\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.4342\n",
      "Document: NASA Aims for May Space Shuttle Launch NASA, recovering from the four hurricanes that halted work at its Florida spaceport, said on Friday it has set a launch target in May, 2005, for the first \n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.4325\n",
      "Document: NASA Picks May 2005 for Launch Date (AP) AP - NASA said Friday it is aiming for a mid-May launch of the first shuttle flight since the Columbia tragedy almost two years ago.\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.4287\n",
      "Document: Nasa shuttle launch hope NASA has said it is aiming for a mid-May launch of the first shuttle flight since the Columbia tragedy in February 2003. The launch date was the latest of several set by the space agency, and just as subject to change.\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.4266\n",
      "Document: NASA Delays Swift Launch Launch of NASA #39;s Swift spacecraft has been delayed at least 24 hours due to a concern with Range Command-Receiver Decoder equipment on the launch vehicle.\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.4083\n",
      "Document: NASA #39;s Satellite Photo of Hurricane Ivan Summary - (Sep 11, 2004) NASA #39;s Terra satellite took this photograph of Hurricane Ivan as it roared past the island of Jamaica on Saturday.\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.4047\n",
      "Document: NASA eyes May launch for Shuttle NASA has announced that the Space Shuttle will take to the skies once more next year, in a launch window that lasts from mid May to early June.\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.3954\n",
      "Document: Iran Plans to Launch Satellite by May 2005 Iran said Thursday it would launch its first satellite into space by May 2005, state television reported. Mohammad Fathi, head of Iran #39;s Scientific and Industrial Research Center, said the \n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.3944\n",
      "Document: NASA Picks May 2005 Shuttle Launch Date NASA (news - web sites) is aiming for a mid-May launch of the first shuttle flight since the Columbia tragedy almost two years ago.\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.3882\n",
      "Document: NASA #39;s DART launch Postponed NASA and Orbital Sciences Corp. have postponed today #39;s launch of the Demonstration of Autonomous Rendezvous Technology (DART) spacecraft because the target satellite, Multiple Paths, Beyond-Line-of-Sight Communications \n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.3863\n",
      "Document: New NASA Spacecraft Moves One Step Closer to Fall Launch NASA -- NASA is planning to launch the Demonstration of Autonomous Rendezvous Technology (DART) flight demonstrator no earlier than Oct. 26, 2004, from Vandenberg Air Force Base, Calif...\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.3842\n",
      "Document: NASA Calls Off Launch of Black Hole Hunter (AP) AP - With just hours left in the countdown, NASA called off the launch Wednesday of a spacecraft that will hunt for emerging black holes.\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.3842\n",
      "Document: NASA Calls Off Launch of Black Hole-Hunter (AP) AP - With just hours left in the countdown, NASA called off the launch Wednesday of a spacecraft that will hunt for emerging black holes.\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.3840\n",
      "Document: NASA Aims For May Shuttle Launch NASA has again adjusted its schedule for bringing the space shuttle back into use. CBS reports that the space agency announced it is aiming for a mid-May launch.\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.3813\n",
      "Document: Satellite radio competitors engaged in a star search The competition between the country #39;s two satellite radio companies began as a race to the stars, with each fighting to be the first to launch satellites into space.\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.3718\n",
      "Document: XM Radio To Launch Online Radio Stations The nation #39;s largest provider of satellite radio will launch a premium internet music service in early October. XM Satellite Radio, the nation #39;s largest provider of satellite radio with more than 2.1 million \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"ag_news\", split=\"train\")\n",
    "documents = [entry['text'] for entry in dataset]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "document_vectors = vectorizer.fit_transform(documents)\n",
    "\n",
    "search(\"NASA satellite launch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
